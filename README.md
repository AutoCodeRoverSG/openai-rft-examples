# Introduction

This repo contains two input-output examples of an LLM (Claude 3.5 Sonnet). The
examples illustrate where the LLM falls short in producing bug fixes compared to
human experts. Key takeaways from the examples are:

1. LLMs may fail to make reasonable generalizations from the issue, resulting in incomplete fixes.

2. LLMs may fail to follow project-specific conventions, leading to incorrect bug fixes.

The examples highlight the importance of fine-tuning LLMs for bug fixing tasks to improve their
real-world usefulness and trustworthiness.
